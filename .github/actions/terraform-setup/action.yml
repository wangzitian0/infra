name: "Terraform Setup"
description: "Sets up Terraform, renders tfvars, configures SSH, and fetches kubeconfig"
inputs:
  terraform_version:
    description: "Terraform version to use"
    required: true
    default: "1.6.6"
  aws_access_key_id:
    description: "AWS Access Key ID for R2"
    required: true
  aws_secret_access_key:
    description: "AWS Secret Access Key for R2"
    required: true
  r2_bucket:
    description: "R2 Bucket Name"
    required: true
  r2_account_id:
    description: "R2 Account ID"
    required: true
  vps_host:
    description: "VPS Host IP/Domain"
    required: true
  vps_ssh_key:
    description: "VPS SSH Private Key"
    required: true
  vps_user:
    description: "VPS User"
    required: false
    default: "root"
  vps_ssh_port:
    description: "VPS SSH Port"
    required: false
    default: "22"
  k3s_cluster_name:
    description: "Cluster Name"
    required: false
  k3s_api_endpoint:
    description: "K3s API Endpoint"
    required: false
  k3s_channel:
    description: "K3s Channel"
    required: false
  k3s_version:
    description: "K3s Version"
    required: false
  infisical_postgres_password:
    description: "Postgres Password"
    required: true

runs:
  using: "composite"
  steps:
    - name: Set up Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: ${{ inputs.terraform_version }}

    - name: Validate secrets
      shell: bash
      env:
        AWS_ACCESS_KEY_ID: ${{ inputs.aws_access_key_id }}
        AWS_SECRET_ACCESS_KEY: ${{ inputs.aws_secret_access_key }}
        R2_BUCKET: ${{ inputs.r2_bucket }}
        R2_ACCOUNT_ID: ${{ inputs.r2_account_id }}
        VPS_HOST: ${{ inputs.vps_host }}
        VPS_SSH_KEY: ${{ inputs.vps_ssh_key }}
      run: |
        set -euo pipefail
        [ -z "${AWS_ACCESS_KEY_ID}" ] && echo "Missing AWS_ACCESS_KEY_ID" && exit 1
        [ -z "${AWS_SECRET_ACCESS_KEY}" ] && echo "Missing AWS_SECRET_ACCESS_KEY" && exit 1
        [ -z "${R2_BUCKET}" ] && echo "Missing R2_BUCKET" && exit 1
        [ -z "${R2_ACCOUNT_ID}" ] && echo "Missing R2_ACCOUNT_ID" && exit 1
        [ -z "${VPS_HOST}" ] && echo "Missing VPS_HOST" && exit 1
        [ -z "${VPS_SSH_KEY}" ] && echo "Missing VPS_SSH_KEY" && exit 1
        [ -z "${{ inputs.github_token }}" ] && echo "Missing github_token" && exit 1
        [ -z "${{ inputs.atlantis_webhook_secret }}" ] && echo "Missing atlantis_webhook_secret" && exit 1
        echo "All required secrets present"

    - name: Render tfvars and SSH
      shell: bash
      env:
        VPS_HOST: ${{ inputs.vps_host }}
        VPS_USER: ${{ inputs.vps_user }}
        VPS_SSH_PORT: ${{ inputs.vps_ssh_port }}
        VPS_SSH_KEY: ${{ inputs.vps_ssh_key }}
        K3S_API_ENDPOINT: ${{ inputs.k3s_api_endpoint }}
        K3S_CHANNEL: ${{ inputs.k3s_channel }}
        K3S_VERSION: ${{ inputs.k3s_version }}
        K3S_CLUSTER_NAME: ${{ inputs.k3s_cluster_name }}
        INFISICAL_POSTGRES_PASSWORD: ${{ inputs.infisical_postgres_password }}
      run: |
        set -euo pipefail

        VPS_USER_VALUE="${VPS_USER:-root}"
        SSH_PORT_VALUE="${VPS_SSH_PORT:-22}"
        CLUSTER_NAME_VALUE="${K3S_CLUSTER_NAME:-truealpha-k3s}"
        API_ENDPOINT_VALUE="${K3S_API_ENDPOINT:-$VPS_HOST}"
        CHANNEL_VALUE="${K3S_CHANNEL:-stable}"
        VERSION_VALUE="${K3S_VERSION:-}"
        PG_PASSWORD="${INFISICAL_POSTGRES_PASSWORD:-CHANGE_ME}"

        # Create tfvars in terraform root
        cat > terraform/terraform.tfvars <<EOFVARS
        vps_host        = "${VPS_HOST}"
        vps_user        = "${VPS_USER_VALUE}"
        ssh_port        = ${SSH_PORT_VALUE}
        ssh_private_key = <<-EOF
        ${VPS_SSH_KEY}
        EOF
        cluster_name    = "${CLUSTER_NAME_VALUE}"
        api_endpoint    = "${API_ENDPOINT_VALUE}"
        k3s_channel     = "${CHANNEL_VALUE}"
        k3s_version     = "${VERSION_VALUE}"
        infisical_postgres_password = "${PG_PASSWORD}"
        EOFVARS

        # Setup SSH for fetching kubeconfig
        mkdir -p ~/.ssh
        echo "${VPS_SSH_KEY}" > ~/.ssh/id_rsa
        chmod 600 ~/.ssh/id_rsa
        ssh-keyscan -p "${SSH_PORT_VALUE}" "${VPS_HOST}" >> ~/.ssh/known_hosts

        echo "CLUSTER_NAME_VALUE=${CLUSTER_NAME_VALUE}" >> "${GITHUB_ENV}"

    - name: Terraform init
      working-directory: terraform
      shell: bash
      env:
        AWS_ACCESS_KEY_ID: ${{ inputs.aws_access_key_id }}
        AWS_SECRET_ACCESS_KEY: ${{ inputs.aws_secret_access_key }}
        R2_BUCKET: ${{ inputs.r2_bucket }}
        R2_ACCOUNT_ID: ${{ inputs.r2_account_id }}
      run: |
        terraform init -input=false \
          -backend-config="bucket=${R2_BUCKET}" \
          -backend-config="endpoints={s3=\"https://${R2_ACCOUNT_ID}.r2.cloudflarestorage.com\"}"

    # Fetch kubeconfig explicity (before Plan, so state refresh works)
    - name: Fetch kubeconfig
      shell: bash
      env:
        VPS_HOST: ${{ inputs.vps_host }}
        VPS_SSH_PORT: ${{ inputs.vps_ssh_port }}
      run: |
        set -euo pipefail
        SSH_PORT="${VPS_SSH_PORT:-22}"
        # We need to access CLUSTER_NAME_VALUE from environment, but inputs are static.
        # However, previous step exported CLUSTER_NAME_VALUE to GITHUB_ENV, which is available to subsequent steps in the same job,
        # BUT composite actions runs don't share GITHUB_ENV immediately in the same 'uses' block logic?
        # Actually GITHUB_ENV writes to file, so it persists.

        # Re-derive CLUSTER_NAME_VALUE for safety if env not picked up
        CLUSTER_NAME_VALUE="${{ inputs.k3s_cluster_name }}"
        if [ -z "${CLUSTER_NAME_VALUE}" ]; then CLUSTER_NAME_VALUE="truealpha-k3s"; fi

        KUBECONFIG_PATH="${GITHUB_WORKSPACE}/terraform/output/${CLUSTER_NAME_VALUE}-kubeconfig.yaml"
        mkdir -p "$(dirname "${KUBECONFIG_PATH}")"
        
        echo "Attempting to fetch kubeconfig from VPS..."
        if ssh -i ~/.ssh/id_rsa -p "${SSH_PORT}" -o StrictHostKeyChecking=no "root@${VPS_HOST}" "sudo cat /etc/rancher/k3s/k3s.yaml" > "${KUBECONFIG_PATH}"; then
          echo "Kubeconfig fetched successfully."
          # Replace localhost with VPS Host
          sed -i "s/127.0.0.1/${VPS_HOST}/g" "${KUBECONFIG_PATH}"
          chmod 600 "${KUBECONFIG_PATH}"
          echo "KUBECONFIG_PATH=${KUBECONFIG_PATH}" >> "${GITHUB_ENV}"
        else
          echo "Warning: Failed to fetch kubeconfig. This is expected if the cluster is not yet deployed."
          rm -f "${KUBECONFIG_PATH}"
        fi
